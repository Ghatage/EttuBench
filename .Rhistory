.jinit()
install.packages()
install.packages("RODBC")
install.packages("RODBC")
library(RODBC)
library(RODBC)
?odbcConnect
con <- odbcConnect("aos.acsu.buffalo.edu", uid="ducthanh", pwd="cse601")
warnings()
con <- odbcConnect("aos.acsu.buffalo.edu", uid="ducthanh", pwd="cse601")
warnings()
con <- odbcConnect("aos.acsu.buffalo.edu:1521", uid="ducthanh", pwd="cse601")
warnings()
con <- odbcConnect("aos.buffalo.edu:1521", uid="ducthanh", pwd="cse601")
warnings()
odbcDataSources()
?odbcDataSources
odbcDataSources()
odbcDataSources()
odbcDataSources()
con <- odbcConnect("cse601_proj", uid="ducthanh", pwd="cse601")
warnings()
odbcDataSources()
?odbcConnect
con <- odbcConnect("cse601_proj1", uid="ducthanh", pwd="cse601")
sqlQuery(con, "select count(*) from CLINICAL_FACT")
sqlQuery(con, "select count(*) from CLINICAL_FACT;")
sqlQuery(con, "select count(*) from CLINICAL_FACT")
?sqlQuery
d <- sqlQuery(con, "select * from TEST_TABLE")
d
sqlQuery(con, "select * from DISEASE")
con <- odbcConnect("cse601_proj1", uid="ducthanh", pwd="cse601")
sqlQuery(con, "select * from DISEASE")
sqlQuery(con, "select * from DISEASE")
con
con <- odbcConnect("cse601_proj1", uid="ducthanh", pwd="cse601")
con
sqlQuery(con, "select * from DISEASE")
sqlQuery(con, "select * from DISEASE;")
?odbcConnect
con <- odbcConnect("cse601_proj1", uid="ducthanh", pwd="cse601", believeNRows = TRUE)
sqlQuery(con, "select * from DISEASE")
con <- odbcConnect("cse601_proj1", uid="ducthanh", pwd="cse601",
believeNRows = FALSE, rows_at_time = 100000)
sqlQuery(con, "select * from DISEASE")
con
close(con)
con <- odbcConnect("cse601_proj1", uid="ducthanh", pwd="cse601",
believeNRows = FALSE, rows_at_time = 1)
sqlQuery(con, "select * from DISEASE")
close(con)
con <- odbcConnect("cse601_proj1", uid="ducthanh", pwd="cse601",
believeNRows = FALSE, rows_at_time = 5)
sqlQuery(con, "select * from DISEASE")
close(con)
con <- odbcConnect("cse601_proj1", uid="ducthanh", pwd="cse601",
believeNRows = FALSE, rows_at_time = 1)
sqlQuery(con, "select * from DISEASE")
close(con)
con <- odbcConnect("cse601_proj1", uid="ducthanh", pwd="cse601",
rows_at_time = 1)
sqlQuery(con, "select * from DISEASE")
close(con)
con <- odbcConnect("cse601_proj1", uid="ducthanh", pwd="cse601",
rows_at_time = 1, readOnlyOptimize = TRUE)
sqlQuery(con, "select * from DISEASE")
close(con)
d <- sqlQuery(con, "select * from DISEASE")
con <- odbcConnect("cse601_proj1", uid="ducthanh", pwd="cse601",
rows_at_time = 1, readOnlyOptimize = TRUE)
d <- sqlQuery(con, "select * from DISEASE")
d
close(con)
con <- odbcConnect("cse601_proj1", uid="ducthanh", pwd="cse601", believeNRows = FALSE,
rows_at_time = 1, readOnlyOptimize = TRUE)
d <- sqlQuery(con, "select * from DISEASE")
d
odbcGetInfo(con)
?sqlQuery
d <- sqlQuery(con, "select * from DISEASE", rows_at_time = 100)
d
d <- sqlQuery(con, "select * from DISEASE", rows_at_time = 100, max = 0)
d
sqlGetResults(con)
sqlQuery(con, "select * from DISEASE", rows_at_time = 100, max = 0)
sqlGetResults(con)
sqlQuery(con, "select * from DISEASE")
sqlQuery(con, "select * from DISEASE")
sqlGetResults(con, believeNRows = FALSE)
odbcGetErrMsg
odbcGetErrMsg()
close(con)
con <- odbcConnect("cse601_proj1", uid="ducthanh", pwd="cse601", readOnlyOptimize = TRUE)
odbcGetInfo(channel)
odbcGetInfo(con)
Tables <- sqlTables(con, schema="SCHEMA")
Tables
Tables <- sqlTables(con, schema="SCHEMA.DATATABLE")
sqlTables(con, schema="SCHEMA.DATATABLE")
sqlQuery(con, "select * from DISEASE")
close(con)
con <- odbcConnect("cse601_proj1", uid="ducthanh", pwd="cse601", readOnlyOptimize = TRUE,
believeNRows=FALSE)
odbcGetInfo(con)
sqlQuery(con, "select * from DISEASE", )
sqlQuery(con, "select * from DISEASE")
con <- odbcConnect("cse601_proj1", uid="ducthanh", pwd="cse601", readOnlyOptimize = TRUE,
believeNRows=FALSE)
odbcGetInfo(con)
sqlQuery(con, "select * from DISEASE")
con <- odbcConnect("cse601_proj1", uid="ducthanh", pwd="cse601", readOnlyOptimize = TRUE)
sqlQuery(con, "select * from DISEASE")
con <- odbcConnect("cse601_proj1", uid="ducthanh", pwd="cse601", readOnlyOptimize = TRUE)
odbcGetInfo(con)
sqlQuery(con, "select * from DISEASE")
con <- odbcConnect("cse601_proj1", uid="ducthanh", pwd="cse601", readOnlyOptimize = TRUE)
odbcGetInfo(con)
sqlQuery(con, "select * from DISEASE")
sqlQuery(con, "select * from disease")
sqlGetResults(con, believeNRows = FALSE)
close(con)
con <- odbcConnect("cse601_proj1", uid="ducthanh", pwd="cse601", readOnlyOptimize = TRUE)
odbcGetInfo(con)
sqlQuery(con, "select * from disease")
close(con)
con <- odbcConnect("cse601_proj1", uid="ducthanh", pwd="cse601", readOnlyOptimize = TRUE)
odbcGetInfo(con)
close(con)
con <- odbcConnect("cse601_proj1", uid="ducthanh", pwd="cse601", readOnlyOptimize = TRUE)
odbcGetInfo(con)
sqlQuery(con, "select * from DISEASE")
sqlGetResults(con, believeNRows = FALSE)
close(con)
con <- odbcConnect("cse601_proj1", uid="ducthanh", pwd="cse601", readOnlyOptimize = TRUE)
odbcGetInfo(con)
sqlQuery(con, "select * from DISEASE;")
sqlGetResults(con, believeNRows = FALSE)
close(con)
sqlQuery(con, "select * from DISEASE")
con <- odbcConnect("cse601_proj1", uid="ducthanh", pwd="cse601", readOnlyOptimize = TRUE)
odbcGetInfo(con)
sqlQuery(con, "select * from DISEASE")
sqlQuery(con, "select * from DISEASE", rows_at_time = 1)
for (i in 1:100) {
sqlQuery(con, "select * from DISEASE", rows_at_time = i)
}
for (i in 1:100) {
d <- sqlQuery(con, "select * from DISEASE", rows_at_time = i)
print(d)
}
d <- sqlQuery(con, "select * from DISEASE", rows_at_time = 0)
d
?odbcConnect
for (i in 1:5) {
print(i)
d <- sqlQuery(con, "select * from DISEASE", rows_at_time = i)
print(d)
d <- sqlGetResults(con)
print(d)
}
?sqlGetResults
odbcGetErrMsg(con)
odbcQuery(con, query = "select * from DISEASE", rows_at_time = 1)
odbcQuery(con, query = "select * from DISEASE", rows_at_time = 1)
odbcFetchRows(con)
odbcQuery(con, query = "select * from DISEASE", rows_at_time = 6)
odbcFetchRows(con)
odbcDataSources()
odbcDataSources()
?odbcDriverConnect
myConn <-odbcDriverConnect("user id=ducthanh;password=cse601;data source=aos.acsu.buffalo.edu:1521/aos.buffalo.edu")
warning()
warnings()
myConn <-odbcDriverConnect("user id=ducthanh;password=cse601;data source=aos.acsu.buffalo.edu:1521/aos.buffalo.edu")
warnings()
odbcDataSources()
library(ROracle)
install.packages("RMySQL")
install.packages(c("curl", "kernlab", "plotly", "RODBC", "rpart.plot", "stringi"))
install.packages("GGally")
install.packages(c("acepack", "BH", "caret", "cluster", "codetools", "coin", "colorspace", "curl", "data.table", "DEoptimR", "earth", "evaluate", "forecast", "ggplot2", "ggrepel", "git2r", "Hmisc", "htmlwidgets", "knitr", "lava", "maptools", "mgcv", "openssl", "party", "plotly", "plotmo", "proto", "quantmod", "R6", "RandomFields", "RandomFieldsUtils", "Rcpp", "RcppArmadillo", "reshape2", "rmarkdown", "ROracle", "rsconnect", "scales", "shiny", "slam", "SparseM", "survival", "yaml"))
install.packages(c("acepack", "BH", "caret", "cluster", "codetools",
install.packages(c("acepack", "BH", "caret", "cluster", "codetools"))
install.packages(c("coin", "colorspace", "curl", "data.table", "DEoptimR", "earth", "evaluate", "forecast", "ggrepel"))
install.packages(c("git2r", "Hmisc", "htmlwidgets", "knitr", "lava", "maptools", "mgcv"))
install.packages(c("openssl", "party", "plotly", "plotmo", "proto", "quantmod", "R6", "RandomFields", "RandomFieldsUtils"))
install.packages(c("Rcpp", "RcppArmadillo", "reshape2", "rmarkdown", "ROracle", "rsconnect", "shiny", "slam"))
install.packages(c("Rcpp", "RcppArmadillo", "reshape2", "rmarkdown",
install.packages(c("reshape2", "rmarkdown", "ROracle", "rsconnect"))
install.packages(c("reshape2", "rmarkdown", "ROracle", "rsconnect"))
install.packages(c("shiny", "slam", "SparseM", "yaml"))
install.packages("RcppArmadillo")
install.packages("Rcpp")
remove.packages("ROracle")
library(ggnet)
library(GGally)
R.version()
R.Version()
data("JSS_papers", package = "corpus.JSS.papers")
install.packages("corpus.JSS.papers", repos = "http://datacube.wu.ac.at/", type = "source")
library("OAIHarvester")
install.packages("OAIHarvester")
library("OAIHarvester")
JSS_papers <- JSS_papers[JSS_papers[,"date"] < "2010-08-05",]
data("JSS_papers", package = "corpus.JSS.papers")
JSS_papers <- JSS_papers[JSS_papers[,"date"] < "2010-08-05",]
data("JSS_papers", package = "corpus.JSS.papers")
JSS_papers <- JSS_papers[JSS_papers[,"date"] < "2010-08-05",]
JSS_papers <- JSS_papers[sapply(JSS_papers[, "description"], Encoding) == "unknown",]
library("tm")
library("XML")
remove_HTML_markup <- function(s) tryCatch({
doc <- htmlTreeParse(paste("<!DOCTYPE html>", s), asText = TRUE, trim = FALSE)
xmlValue(xmlRoot(doc))
}, error = function(s) s)
corpus <- Corpus(VectorSource(sapply(JSS_papers[, "description"], remove_HTML_markup)))
Sys.setlocale("LC_COLLATE", "C")
JSS_dtm <- DocumentTermMatrix(corpus,
control = list(stemming = TRUE, stopwords = TRUE,
minWordLength = 3, removeNumbers = TRUE,
removePunctuation = TRUE))
dim(JSS_dtm)
library("slam")
summary(col_sums(JSS_dtm))
term_tfidf <- tapply(JSS_dtm$v/row_sums(JSS_dtm)[JSS_dtm$i],
JSS_dtm$j, mean) * log2(nDocs(JSS_dtm)/col_sums(JSS_dtm > 0))
summary(term_tfidf)
JSS_dtm <- JSS_dtm[,term_tfidf >= 0.1]
JSS_dtm <- JSS_dtm[row_sums(JSS_dtm) > 0,]
summary(col_sums(JSS_dtm))
dim(JSS_dtm)
library("topicmodels")
install.packages("topicmodels")
library("topicmodels")
k <- 30
SEED <- 2010
jss_TM <- list(VEM = LDA(JSS_dtm, k = k, control = list(seed = SEED)),
VEM_fixed = LDA(JSS_dtm, k = k,
control = list(estimate.alpha = FALSE, seed = SEED)),
Gibbs = LDA(JSS_dtm, k = k, method = "Gibbs",
control = list(seed = SEED, burnin = 1000,
thin = 100, iter = 1000)),
CTM = CTM(JSS_dtm, k = k,
control = list(seed = SEED,
var = list(tol = 10^-4), em = list(tol = 10^-3))))
sapply(jss_TM[1:2], slot, "alpha")
sapply(jss_TM, function(x) mean(apply(posterior(x)$topics, 1, function(z) - sum(z * log(z)))))
(topics_v24 <- topics(jss_TM[["VEM"]])[grep("/v24/", JSS_papers[, "identifier"])])
most_frequent_v24 <- which.max(tabulate(topics_v24))
terms(jss_TM[["VEM"]], 10)[, most_frequent_v24]
data("JSS_papers", package = "corpus.JSS.papers")
data("JSS_papers", package = "corpus.JSS.papers")
JSS_papers <- JSS_papers[JSS_papers[,"date"] < "2010-08-05",]
JSS_papers <- JSS_papers[sapply(JSS_papers[, "description"], Encoding) == "unknown",]
JSS_papers <- JSS_papers[sapply(JSS_papers[, "description"], Encoding) == "unknown",]
library("tm")
library("XML")
remove_HTML_markup <- function(s) tryCatch({
doc <- htmlTreeParse(paste("<!DOCTYPE html>", s), asText = TRUE, trim = FALSE)
xmlValue(xmlRoot(doc))
}, error = function(s) s)
corpus <- Corpus(VectorSource(sapply(JSS_papers[, "description"], remove_HTML_markup)))
Sys.setlocale("LC_COLLATE", "C")
JSS_dtm <- DocumentTermMatrix(corpus,
control = list(stemming = TRUE, stopwords = TRUE,
minWordLength = 3, removeNumbers = TRUE,
removePunctuation = TRUE))
dim(JSS_dtm)
class(JSS_dtm)
library("slam")
summary(col_sums(JSS_dtm))
JSS_dtm$v
JSS_dtm$j
JSS_dtm$dimnames
nDocs(JSS_dtm)
dim(JSS_dtm)
summary(term_tfidf)
term_tfidf <- tapply(JSS_dtm$v/row_sums(JSS_dtm)[JSS_dtm$i],
JSS_dtm$j, mean) * log2(nDocs(JSS_dtm)/col_sums(JSS_dtm > 0))
term_tfidf
class(term_tfidf)
sum(term_tfidf)
summary(term_tfidf)
JSS_dtm <- JSS_dtm[,term_tfidf >= 0.1]
JSS_dtm <- JSS_dtm[row_sums(JSS_dtm) > 0,]
dim(JSS_dtm)
summary(col_sums(JSS_dtm))
dim(JSS_dtm)
library("topicmodels")
k <- 30
SEED <- 2010
jss_TM <- list(VEM = LDA(JSS_dtm, k = k, control = list(seed = SEED)),
VEM_fixed = LDA(JSS_dtm, k = k,
control = list(estimate.alpha = FALSE, seed = SEED)),
Gibbs = LDA(JSS_dtm, k = k, method = "Gibbs",
control = list(seed = SEED, burnin = 1000,
thin = 100, iter = 1000)),
CTM = CTM(JSS_dtm, k = k,
control = list(seed = SEED,
var = list(tol = 10^-4), em = list(tol = 10^-3))))
sapply(jss_TM[1:2], slot, "alpha")
sapply(jss_TM[1:2], slot, "alpha")
sapply(jss_TM, function(x) mean(apply(posterior(x)$topics, 1, function(z) - sum(z * log(z)))))
Topic <- topics(jss_TM[["VEM"]], 1)
Topic
Terms <- terms(jss_TM[["VEM"]], 5)
Terms[,1:5]
(topics_v24 <- topics(jss_TM[["VEM"]])[grep("/v24/", JSS_papers[, "identifier"])])
most_frequent_v24 <- which.max(tabulate(topics_v24))
terms(jss_TM[["VEM"]], 10)[, most_frequent_v24]
?list.dirs
list.dir(data_path)
data_path <- "/Users/anhduc/study/Insider Threats/PhoneLab_data"
list.dir(data_path)
list.dirs(data_path, recursive = FALSE)
list_device_path <- list.dirs(data_path, recursive = FALSE)
for (device_path in list_device_path) {
print(device_path)
}
for (device_path in list_device_path) {
list.files(device_path + "/tag/SQLite-Query-PhoneLab/2015/03/")
}
for (device_path in list_device_path) {
list.files(paste0(device_path, "/tag/SQLite-Query-PhoneLab/2015/03/"))
}
device_path <- list_device_path[[1]]
device_path
paste0(device_path, "/tag/SQLite-Query-PhoneLab/2015/03/")
list.files(paste0(device_path, "/tag/SQLite-Query-PhoneLab/2015/03/"))
for (device_path in list_device_path) {
print(list.files(paste0(device_path, "/tag/SQLite-Query-PhoneLab/2015/03/")))
}
library(rjson)
library(rjson)
file_list <- list.files(paste0(device_path, "/tag/SQLite-Query-PhoneLab/2015/03/"))
filename <- file_list[[1]]
records <- fromJSON(file = paste0(device_path, filename))
records <- fromJSON(file = paste0(device_path, "/",filename))
records <- fromJSON(file = paste0(device_path, "/tag/SQLite-Query-PhoneLab/2015/03/",filename))
records
records <- fromJSON(file = paste0(device_path, "/tag/SQLite-Query-PhoneLab/2015/03/",filename))
filename <- file_list[[2]]
records <- fromJSON(file = paste0(device_path, "/tag/SQLite-Query-PhoneLab/2015/03/",filename))
install.packages("rjsonio")
install.packages("RJSONIO")
install.packages(c("backports", "chron", "clue", "colorspace", "Cubist", "data.table", "data.tree", "dbscan", "dendextend", "DiagrammeR", "digest", "e1071", "expm", "factoextra", "fields", "ggfortify", "ggplot2", "git2r", "googleVis", "HistData", "Hmisc", "htmlTable", "jsonlite", "KFAS", "lava", "maptools", "Matrix", "mclust", "nlme", "OAIHarvester", "openssl", "plotrix", "pls", "pROC", "prodlim", "progress", "proxy", "RandomFields", "RandomFieldsUtils", "Rcpp", "RcppArmadillo", "rgl", "rmarkdown", "robustbase", "roxygen2", "rprojroot", "rsconnect", "scatterplot3d", "shiny", "skmeans", "sp", "TH.data", "tidyr", "tseries", "visNetwork", "zoo"))
detach("package:rjson", unload=TRUE)
library(RJSONIO)
records <- fromJSON(file = paste0(device_path, "/tag/SQLite-Query-PhoneLab/2015/03/",filename))
?fromJSON
?cexp
10 * exp(12/10)
install.packages(c("assertthat", "boot", "caret", "cts", "curl", "earth", "flexmix", "foreign", "formatR", "gam", "Hmisc", "htmltools", "KFAS", "lme4", "markdown", "MASS", "Matrix", "memoise", "party", "plotly", "plotmo", "quantmod", "quantreg", "RandomFields", "RandomFieldsUtils", "RcppArmadillo", "RcppEigen", "rmarkdown", "RODBC", "rpart", "rpart.plot", "rstan", "scatterplot3d", "shiny", "SparseM", "splancs", "StanHeaders", "tidyr", "topicmodels", "tseries", "XML", "zoo"))
R.version()
version()
R.Version()
(20121.14 - 1946.88 - 485.68 - 2629.38) / (13 * 2)
(20121.14 - 1946.88 - 485.68 - 2629.38) / (12 * 2)
680.44	* 13 * 2
680.44	* 13 * 2 + 1946.88 + 485.68
(1946.88 + 485.68) / 20121.14
20121.14 / 12
680.44 * 2 / 1676.762
rbeta(-1,-1)
?rbeta
rbeta(1, -1,-1)
rbeta(1, shape1=-1,shape2=-1)
setwd("~/github/EttuBench")
setwd("~/github/EttuBench")
source(file = "./evaluation.R")
source(file = "./utils.R")
library(cluster)
library(factoextra)
install.packages("factoextra")
library(RColorBrewer)
dataset <- read.csv(file = "./data/bombay_queries.csv", header = TRUE, sep = "\t")
distMat <- readDistMat("./data/bombay_aligon.csv")
silhouettePlot(distMat, dataset$label, "./figure/sil_bombay_Aligon.pdf")
library(factoextra)
library(RColorBrewer)
library(cluster)
dataset <- read.csv(file = "./data/bombay_queries.csv", header = TRUE, sep = "\t")
distMat <- readDistMat("./data/bombay_aligon.csv")
silhouettePlot(distMat, dataset$label, "./figure/sil_bombay_Aligon.pdf")
distMat <- readDistMat("./data/bombay_aligon_regularization.csv")
silhouettePlot(distMat, dataset$label, "./figure/sil_bombay_Aligon_regularization.pdf")
dataset <- read.csv(file = "./data/ub_queries.csv", header = TRUE, sep = "\t")
distMat <- readDistMat("./data/ub_aligon.csv")
silhouettePlot(distMat, dataset$label, "./figure/sil_ub_Aligon.pdf")
distMat <- readDistMat("./data/ub_aligon_regularization.csv")
silhouettePlot(distMat, dataset$label, "./figure/sil_ub_Aligon_regularization.pdf")
dataset <- read.csv(file = "./data/googleplus_queries.csv", header = TRUE, sep = "\t")
distMat <- readDistMat("./data/googleplus_aligon.csv")
silhouettePlot(distMat, dataset$label, "./figure/sil_googleplus_Aligon.pdf")
distMat <- readDistMat("./data/googleplus_aligon_regularization.csv")
silhouettePlot(distMat, dataset$label, "./figure/sil_googleplus_Aligon_regularization.pdf")
library(ggplot2)
comparison <- read.csv(file = "./data/result.csv", header = TRUE)
comparison
library(ggplot2)
comparison <- read.csv(file = "./data/result.csv", header = TRUE)
comparison$dataset <- factor(comparison$dataset,
levels = c("IIT Bombay Dataset",
"Local Exam Dataset",
"PocketData-Google+"))
ggplot(data = comparison, aes(x = metric, y = silhouette, fill = regularization)) +
geom_bar(position="dodge", stat="identity") + facet_grid(~ dataset) +
ylab("Average Silhouette Coefficient") + xlab("Metric") +
theme_bw(base_size = 18) + theme(legend.position = "top") + scale_fill_grey() +
ggsave(filename = "./figure/compare_silhouette.pdf")
ggplot(data = comparison, aes(x = metric, y = beta_cv, fill = regularization)) +
geom_bar(position="dodge", stat="identity") + facet_grid(~ dataset) +
ylab("Average Silhouette Coefficient") + xlab("Metric") +
theme_bw(base_size = 18) + theme(legend.position = "top") + scale_fill_grey() +
ggsave(filename = "./figure/compare_betacv.pdf")
ggplot(data = comparison, aes(x = metric, y = dunn, fill = regularization)) +
geom_bar(position="dodge", stat="identity") + facet_grid(~ dataset) +
ylab("Average Silhouette Coefficient") + xlab("Metric") +
theme_bw(base_size = 18) + theme(legend.position = "top") + scale_fill_grey() +
ggsave(filename = "./figure/compare_dunn.pdf")
library(ggplot2)
comparison <- read.csv(file = "./data/modules.csv")
comparison$Regularization <- factor(comparison$Regularization,
levels = c("No Regularization",
"Naming",
"Expression Standardization",
"FROM-nested Subquery",
"UNION Pull-out"))
comparison$Dataset <- factor(comparison$Dataset,
levels = c("IIT Bombay Dataset", "Local Exam Dataset",
"PhoneLab-Google+"))
ggplot(data = comparison, aes(x = Metric, y = Silhouette, fill=Regularization)) +
geom_bar(position="dodge", stat="identity") + facet_grid(~ Dataset) +
ylab("Average Silhouette Coefficient") + xlab("Metric") +
theme_bw(base_size = 14) + theme(legend.position = "top", legend.title = element_blank()) +
scale_fill_brewer(palette = "Dark2") +
ggsave(file = "./figure/module.pdf")
setwd("~/github/EttuBench")
source(file = "./evaluation.R")
source(file = "./utils.R")
library(cluster)
library(factoextra)
library(RColorBrewer)
dataset <- read.csv(file = "./data/googleplus_queries.csv", header = TRUE, sep = "\t")
distMat <- readDistMat("./data/googleplus_aligon.csv")
sil <- silhouette(label, as.dist(distMat))
sil <- silhouette(dataset$label, as.dist(distMat))
sil
sil
sil$coef
write.csv("temp.csv", sil)
write.csv(file = "temp.csv", sil)
distMat <- readDistMat("./data/googleplus_makiyama.csv")
sil <- silhouette(dataset$label, as.dist(distMat))
write.csv(file = "temp.csv", sil)
distMat <- readDistMat("./data/googleplus_aligon_regularization.csv")
sil <- silhouette(dataset$label, as.dist(distMat))
write.csv(file = "temp.csv", sil)
distMat <- readDistMat("./data/googleplus_makiyama_regularization.csv")
sil <- silhouette(dataset$label, as.dist(distMat))
write.csv(file = "temp.csv", sil)
setwd("~/github/EttuBench")
library(ggplot2)
comparison <- read.csv(file = "./data/result.csv", header = TRUE)
comparison$dataset <- factor(comparison$dataset,
levels = c("IIT Bombay Dataset",
"Local Exam Dataset",
"PocketData-Google+"))
ggplot(data = comparison, aes(x = metric, y = silhouette, fill = regularization)) +
geom_bar(position="dodge", stat="identity") + facet_grid(~ dataset) +
ylab("Average Silhouette Coefficient") + xlab("Metric") +
theme_bw(base_size = 18) + theme(legend.position = "top") + scale_fill_grey() +
ggsave(filename = "./figure/compare_silhouette.pdf")
library(ggplot2)
comparison <- read.csv(file = "./data/result.csv", header = TRUE)
comparison$dataset <- factor(comparison$dataset,
levels = c("IIT Bombay Dataset",
"UB Exam Dataset",
"PocketData-Google+"))
ggplot(data = comparison, aes(x = metric, y = silhouette, fill = regularization)) +
geom_bar(position="dodge", stat="identity") + facet_grid(~ dataset) +
ylab("Average Silhouette Coefficient") + xlab("Metric") +
theme_bw(base_size = 18) + theme(legend.position = "top") + scale_fill_grey() +
ggsave(filename = "./figure/compare_silhouette.pdf")
ggplot(data = comparison, aes(x = metric, y = beta_cv, fill = regularization)) +
geom_bar(position="dodge", stat="identity") + facet_grid(~ dataset) +
ylab("Average Silhouette Coefficient") + xlab("Metric") +
theme_bw(base_size = 18) + theme(legend.position = "top") + scale_fill_grey() +
ggsave(filename = "./figure/compare_betacv.pdf")
ggplot(data = comparison, aes(x = metric, y = dunn, fill = regularization)) +
geom_bar(position="dodge", stat="identity") + facet_grid(~ dataset) +
ylab("Average Silhouette Coefficient") + xlab("Metric") +
theme_bw(base_size = 18) + theme(legend.position = "top") + scale_fill_grey() +
ggsave(filename = "./figure/compare_dunn.pdf")
library(ggplot2)
comparison <- read.csv(file = "./data/modules.csv")
comparison$Regularization <- factor(comparison$Regularization,
levels = c("No Regularization",
"Naming",
"Expression Standardization",
"FROM-nested Subquery",
"UNION Pull-out"))
comparison$Dataset <- factor(comparison$Dataset,
levels = c("IIT Bombay Dataset", "UB Exam Dataset",
"PhoneLab-Google+"))
ggplot(data = comparison, aes(x = Metric, y = Silhouette, fill=Regularization)) +
geom_bar(position="dodge", stat="identity") + facet_grid(~ Dataset) +
ylab("Average Silhouette Coefficient") + xlab("Metric") +
theme_bw(base_size = 14) + theme(legend.position = "top", legend.title = element_blank()) +
scale_fill_brewer(palette = "Dark2") +
ggsave(file = "./figure/module.pdf")
